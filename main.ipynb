{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape IMDB for list of movie titles\n",
    "def getTitles(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    header = soup.find_all('h3', class_='lister-item-header')\n",
    "\n",
    "    titles = []\n",
    "    for item in header:\n",
    "        titles.append(item.find('a').get_text())\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find ZH wiki page link to each movie title\n",
    "def getLinks(titles):\n",
    "    links = []\n",
    "    for idx, title in enumerate(titles):\n",
    "        title = title.replace(' ','_')\n",
    "        print('Now processing title number' + str(idx))\n",
    "        try:\n",
    "            try:\n",
    "                tmp = []\n",
    "                path = 'https://en.wikipedia.org/wiki/' + title + '_(film)'\n",
    "                page = requests.get(path)\n",
    "                soup = BeautifulSoup(page.content, 'html.parser')\n",
    "                li = soup.find('li', class_='interlanguage-link interwiki-zh')\n",
    "                lin = li.find('a')\n",
    "                link = lin['href']\n",
    "                links.append(link)\n",
    "            except:\n",
    "                tmp = []\n",
    "                path = 'https://en.wikipedia.org/wiki/' + title\n",
    "                page = requests.get(path)\n",
    "                soup = BeautifulSoup(page.content, 'html.parser')\n",
    "                li = soup.find('li', class_='interlanguage-link interwiki-zh')\n",
    "                lin = li.find('a')\n",
    "                link = lin['href']\n",
    "                links.append(link)\n",
    "        except:\n",
    "            links.append('404')\n",
    "            print('Not Found.')\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 3 translated titles of China, Hong Kong and Taiwan:\n",
    "def getTranslation(links):\n",
    "    titlesCH = []\n",
    "    titlesHK = []\n",
    "    titlesTW = []\n",
    "    for link in links:\n",
    "        try:\n",
    "            page = requests.get(link)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            table = soup.find('table', class_='infobox vevent')\n",
    "            td = table.find_all('td')[-3:]\n",
    "            titlesCH.append(td[0].get_text())\n",
    "            titlesHK.append(td[1].get_text())\n",
    "            titlesTW.append(td[2].get_text())\n",
    "        except:\n",
    "            titlesCH.append('null')\n",
    "            titlesHK.append('null')\n",
    "            titlesTW.append('null')\n",
    "    return titlesCH, titlesHK, titlesTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbPath = 'https://www.imdb.com/search/title?year=2016&title_type=feature&sort=num_votes,desc&page=4&ref_=adv_nxt'\n",
    "titles = getTitles(imdbPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing title number0\n",
      "Now processing title number1\n",
      "Not Found.\n",
      "Now processing title number2\n",
      "Not Found.\n",
      "Now processing title number3\n",
      "Not Found.\n",
      "Now processing title number4\n",
      "Not Found.\n",
      "Now processing title number5\n",
      "Not Found.\n",
      "Now processing title number6\n",
      "Not Found.\n",
      "Now processing title number7\n",
      "Not Found.\n",
      "Now processing title number8\n",
      "Now processing title number9\n",
      "Now processing title number10\n",
      "Now processing title number11\n",
      "Not Found.\n",
      "Now processing title number12\n",
      "Not Found.\n",
      "Now processing title number13\n",
      "Now processing title number14\n",
      "Not Found.\n",
      "Now processing title number15\n",
      "Now processing title number16\n",
      "Not Found.\n",
      "Now processing title number17\n",
      "Not Found.\n",
      "Now processing title number18\n",
      "Now processing title number19\n",
      "Now processing title number20\n",
      "Not Found.\n",
      "Now processing title number21\n",
      "Now processing title number22\n",
      "Not Found.\n",
      "Now processing title number23\n",
      "Now processing title number24\n",
      "Not Found.\n",
      "Now processing title number25\n",
      "Not Found.\n",
      "Now processing title number26\n",
      "Not Found.\n",
      "Now processing title number27\n",
      "Now processing title number28\n",
      "Now processing title number29\n",
      "Now processing title number30\n",
      "Not Found.\n",
      "Now processing title number31\n",
      "Not Found.\n",
      "Now processing title number32\n",
      "Not Found.\n",
      "Now processing title number33\n",
      "Now processing title number34\n",
      "Now processing title number35\n",
      "Not Found.\n",
      "Now processing title number36\n",
      "Now processing title number37\n",
      "Now processing title number38\n",
      "Not Found.\n",
      "Now processing title number39\n",
      "Now processing title number40\n",
      "Not Found.\n",
      "Now processing title number41\n",
      "Not Found.\n",
      "Now processing title number42\n",
      "Not Found.\n",
      "Now processing title number43\n",
      "Not Found.\n",
      "Now processing title number44\n",
      "Now processing title number45\n",
      "Now processing title number46\n",
      "Now processing title number47\n",
      "Not Found.\n",
      "Now processing title number48\n",
      "Not Found.\n",
      "Now processing title number49\n",
      "Not Found.\n"
     ]
    }
   ],
   "source": [
    "links = getLinks(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlesCH, titlesHK, titlesTW = getTranslation(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/openpyxl/reader/worksheet.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'TitlesEN': titles,\n",
    "    'TitlesCH': titlesCH,\n",
    "    'TitlesHK': titlesHK,\n",
    "    'TitlesTW': titlesTW,\n",
    "    'wikiZH': links\n",
    "})\n",
    "\n",
    "# Write to an existing excel file and create new sheet\n",
    "with pd.ExcelWriter('final.xlsx', engine='openpyxl') as writer:\n",
    "    writer.book = load_workbook('final.xlsx')\n",
    "    results.to_excel(writer, sheet_name='2016_p4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
