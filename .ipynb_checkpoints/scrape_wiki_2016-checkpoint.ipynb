{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deadpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Batman v Superman: Dawn of Justice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Captain America: Civil War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suicide Squad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrival</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Titles\n",
       "0                            Deadpool\n",
       "1  Batman v Superman: Dawn of Justice\n",
       "2          Captain America: Civil War\n",
       "3                       Suicide Squad\n",
       "4                             Arrival"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('titles2016.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = df['Titles']\n",
    "type(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing title number0\n",
      "Now processing title number1\n",
      "Now processing title number2\n",
      "Now processing title number3\n",
      "Now processing title number4\n",
      "Now processing title number5\n",
      "Now processing title number6\n",
      "Now processing title number7\n",
      "Now processing title number8\n",
      "Not Found.\n",
      "Now processing title number9\n",
      "Now processing title number10\n",
      "Now processing title number11\n",
      "Now processing title number12\n",
      "Now processing title number13\n",
      "Not Found.\n",
      "Now processing title number14\n",
      "Now processing title number15\n",
      "Now processing title number16\n",
      "Now processing title number17\n",
      "Not Found.\n",
      "Now processing title number18\n",
      "Now processing title number19\n",
      "Now processing title number20\n",
      "Now processing title number21\n",
      "Now processing title number22\n",
      "Not Found.\n",
      "Now processing title number23\n",
      "Now processing title number24\n",
      "Now processing title number25\n",
      "Now processing title number26\n",
      "Not Found.\n",
      "Now processing title number27\n",
      "Now processing title number28\n",
      "Now processing title number29\n",
      "Now processing title number30\n",
      "Not Found.\n",
      "Now processing title number31\n",
      "Now processing title number32\n",
      "Now processing title number33\n",
      "Now processing title number34\n",
      "Now processing title number35\n",
      "Now processing title number36\n",
      "Now processing title number37\n",
      "Now processing title number38\n",
      "Now processing title number39\n",
      "Now processing title number40\n",
      "Now processing title number41\n",
      "Now processing title number42\n",
      "Now processing title number43\n",
      "Not Found.\n",
      "Now processing title number44\n",
      "Now processing title number45\n",
      "Now processing title number46\n",
      "Not Found.\n",
      "Now processing title number47\n",
      "Now processing title number48\n",
      "Now processing title number49\n"
     ]
    }
   ],
   "source": [
    "for idx, title in enumerate(titles):\n",
    "    title = title.replace(' ','_')\n",
    "    print('Now processing title number' + str(idx))\n",
    "    try:\n",
    "        try:\n",
    "            tmp = []\n",
    "            path = 'https://en.wikipedia.org/wiki/' + title + '_(film)'\n",
    "            page = requests.get(path)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            li = soup.find('li', class_='interlanguage-link interwiki-zh')\n",
    "            lin = li.find('a')\n",
    "            link = lin['href']\n",
    "            links.append(link)\n",
    "        except:\n",
    "            tmp = []\n",
    "            path = 'https://en.wikipedia.org/wiki/' + title\n",
    "            page = requests.get(path)\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            li = soup.find('li', class_='interlanguage-link interwiki-zh')\n",
    "            lin = li.find('a')\n",
    "            link = lin['href']\n",
    "            links.append(link)\n",
    "    except:\n",
    "        links.append('404')\n",
    "        print('Not Found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save links to csv\n",
    "linksdf = pd.DataFrame(data={\"links\": links})\n",
    "linksdf.to_csv(\"linksZH_2016.csv\", sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
